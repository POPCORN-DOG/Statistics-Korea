{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen #url의 html 을 가져 오기 위한 패키지\n",
    "from bs4 import BeautifulSoup  #크롤링 필수 패키지 설치하려면 cmd창에서 pip install bs4\n",
    "import os\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup #크롤링 도구\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pylab as pl\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import DBSCAN\n",
    "import sklearn as skl\n",
    "import sklearn.model_selection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from ckonlpy.tag import Twitter\n",
    "import string\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from matplotlib import font_manager, rc\n",
    "from ckonlpy.tag import Postprocessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "try:\n",
    "    data = pd.read_excel('C:/Users/USER/Desktop/통계용어사업data.xlsx')\n",
    "    data['words'] = [i.replace(\"'\", \"\").replace('[', '').replace(']', '').replace(' ', '').split(',') for i in\n",
    "                    list(data['words'])]  # words가 텍스트 형식으로 되어 있을 경우\n",
    "except:\n",
    "    #2018, 19, 20 일부 뉴스 가져와서 합치기\n",
    "    #2018년 뉴스\n",
    "    data2018= pd.read_excel('C:/Users/USER/Desktop/2018newsdata1105.xlsx', index_col=0)\n",
    "\n",
    "    #2019년 뉴스\n",
    "    data2019 = pd.read_excel('C:/Users/USER/Desktop/data1015.xlsx', index_col=0)\n",
    "\n",
    "    #2020년 뉴스\n",
    "    data2020 = pd.read_excel('C:/Users/USER/Desktop/1~8newsurl/data0928.xlsx', index_col=0)\n",
    "\n",
    "    #통합 데이터 만들기\n",
    "    colnames = ['date','title','text','category','words']\n",
    "    data2018['date'] = [datetime.datetime.strptime(str(i), '%Y%m%d') for i in data2018['date']] #date변수 date타입으로 바꿔주기\n",
    "    data = pd.concat([data2018[colnames],data2019[colnames],data2020[colnames]])\n",
    "    data.to_excel('C:/Users/USER/Desktop/통계용어사업data.xlsx', index= False)\n",
    "    del data2018; del data2019; del data2020;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141365\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(type(data['words'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Word2Vec(data['words'], size=100, window = 5, min_count=5, workers=4, iter=100)\n",
    "embedding_model.save('C:/Users/USER/Desktop/고용단어분류_w2v_min5.model') # 모델 저장\n",
    "\n",
    "embedding_model2 = Word2Vec(data['words'], size=100, window = 5, min_count=50, workers=4, iter=100)\n",
    "embedding_model2.save('C:/Users/USER/Desktop/고용단어분류_w2v_min50.model') # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################텍스트 분석 언더바 해서 \n",
    "data2018 = pd.read_excel('C:/Users/USER/Desktop/통계용어사업data2018.xlsx')\n",
    "\n",
    "#단어 데이터 불러오기\n",
    "work_word_data = pd.read_excel('C:/Users/USER/Desktop/고용관련단어.xlsx')\n",
    "#단어 리스트 만들기\n",
    "work_word_list = [i for i in work_word_data['선정용어']]\n",
    "work_word_list\n",
    "\n",
    "#밑줄 단어 만들기\n",
    "work_word_list2 = []\n",
    "for i in  work_word_list:\n",
    "    work_word_list2.append(i.replace(' ','_'))\n",
    "\n",
    "#띄어쓰기 없는단어 만들기\n",
    "work_word_list3 = []\n",
    "for i in  work_word_list:\n",
    "    work_word_list3.append(i.replace(' ',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 23930/23930 [1:26:24<00:00,  4.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 23930/23930 [00:06<00:00, 3844.40it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#단어 리스트 형태소 분석기에 넣기\n",
    "twi = Twitter()\n",
    "for i in range(len(work_word_list2)):\n",
    "    twi.add_dictionary(work_word_list2[i],'Noun')\n",
    "    twi.add_dictionary(work_word_list[i],'Noun')\n",
    "    twi.add_dictionary(work_word_list3[i],'Noun')\n",
    "\n",
    "#통합어 딕셔너리 만들기\n",
    "replace = {}\n",
    "for i in range(len(work_word_list2)):\n",
    "    replace[work_word_list2[i]] = work_word_list[i]\n",
    "    replace[work_word_list3[i]] = work_word_list[i]\n",
    "\n",
    "#분석할 데이터 셋 만들기 2018년도만 가져오기\n",
    "postprocessor = Postprocessor(base_tagger=twi, replace=replace, passtags={'Noun'})\n",
    "under_bar_text = [m.replace(' ','_') for m in data2018['text']]\n",
    "#형태소 분석 하기\n",
    "words = [[j[i][0] for i in range(len(j))] for j in [postprocessor.pos(i) for i in tqdm(under_bar_text)]]\n",
    "\n",
    "#배제어 등록하기\n",
    "Prohibit_words = ['기자','연합뉴스','뉴시스','시사저널','신문','뉴스','사진','헤럴드경제','노컷뉴스','파이낸셜뉴스','특파원',\n",
    "                  '라며','대해','지난','위해','오전','오후','무단','배포','이데일리','머니투데이','앵커','지금','때문','이번',\n",
    "                  '통해','정도','경우','관련','이미지','출처','일보','바로가기','까지','여개','도록','이나','재배포','처럼','면서',\n",
    "                  '거나','이제','지난달','어요']\n",
    "\n",
    "#배제어 제거, 한 글자 제거하기\n",
    "j = 0\n",
    "for i in tqdm(words):\n",
    "    for k in Prohibit_words:\n",
    "        while k in i:\n",
    "            i.remove(k)\n",
    "    words[j] = i\n",
    "    j += 1 #불용어 제외\n",
    "\n",
    "for k in range(len(words)):\n",
    "    words[k] = [i for i in words[k] if len(i) > 1]  # 한글자 제외\n",
    "\n",
    "data2018['words2'] = words\n",
    "data2018.to_excel('C:/Users/USER/Desktop/통계용어사업data2018_2.0.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 192,\n",
       " 435,\n",
       " 618,\n",
       " 130,\n",
       " 38,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 11,\n",
       " 459,\n",
       " 81,\n",
       " 22,\n",
       " 2346,\n",
       " 3,\n",
       " 138,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 1115,\n",
       " 754,\n",
       " 144,\n",
       " 1311,\n",
       " 26,\n",
       " 2,\n",
       " 90,\n",
       " 0,\n",
       " 0,\n",
       " 122,\n",
       " 0,\n",
       " 0,\n",
       " 1905,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 10,\n",
       " 1507,\n",
       " 0,\n",
       " 1,\n",
       " 21,\n",
       " 42,\n",
       " 33,\n",
       " 61,\n",
       " 0,\n",
       " 2,\n",
       " 1476,\n",
       " 40,\n",
       " 199,\n",
       " 1,\n",
       " 1,\n",
       " 2282,\n",
       " 1,\n",
       " 17,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 53,\n",
       " 2,\n",
       " 0,\n",
       " 266,\n",
       " 88,\n",
       " 106,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 6,\n",
       " 12,\n",
       " 48,\n",
       " 1,\n",
       " 1,\n",
       " 12,\n",
       " 5,\n",
       " 11,\n",
       " 4079,\n",
       " 11,\n",
       " 0,\n",
       " 41,\n",
       " 0,\n",
       " 0,\n",
       " 39,\n",
       " 9,\n",
       " 27,\n",
       " 24,\n",
       " 0,\n",
       " 0,\n",
       " 152,\n",
       " 0,\n",
       " 532,\n",
       " 256,\n",
       " 8,\n",
       " 5026,\n",
       " 327,\n",
       " 0,\n",
       " 0,\n",
       " 124,\n",
       " 0,\n",
       " 416,\n",
       " 35,\n",
       " 219,\n",
       " 3,\n",
       " 0,\n",
       " 33,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 39,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 5308,\n",
       " 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for i in work_word_list:\n",
    "    k= 0\n",
    "    for j in data2018['words2']:\n",
    "        if i in j:\n",
    "            k += 1\n",
    "    a.append(k)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(a).to_excel('C:/Users/USER/Desktop/8.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
