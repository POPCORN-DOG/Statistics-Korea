{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen #url의 html 을 가져 오기 위한 패키지\n",
    "from bs4 import BeautifulSoup  #크롤링 필수 패키지 설치하려면 cmd창에서 pip install bs4\n",
    "import os\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup #크롤링 도구\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pylab as pl\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import DBSCAN\n",
    "import sklearn as skl\n",
    "import sklearn.model_selection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from ckonlpy.tag import Twitter\n",
    "import string\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from matplotlib import font_manager, rc\n",
    "from ckonlpy.tag import Postprocessor\n",
    "#모델 데이터 불러오기\n",
    "data50 = pd.read_excel('C:/Users/USER/Desktop/1~8newsurl/data0923.xlsx', index_col=0)#데이터 불러오기\n",
    "embedding_model = KeyedVectors.load_word2vec_format('C:/Users/USER/Desktop/1~8newsurl/w2v0923') # 모델 로드\n",
    "data50['words'] = [i.replace(\"'\", \"\").replace('[', '').replace(']', '').replace(' ', '').split(',') for i in\n",
    "          list(data50['words'])]  # words가 텍스트 형식으로 되어 있을 경우\n",
    "\n",
    "#3글자 부터 밎 주요 2단어 포함\n",
    "data = data50.reset_index(drop=True)\n",
    "words = list(data['words'])\n",
    "for k in range(len(words)):\n",
    "    words[k] = [i for i in words[k] if len(i) > 2 or i in ['배달','택배','고용','취업','실업','채용','구직','청년','유통','해고']]  # 두글자 이하 제외\n",
    "data['words'] = words\n",
    "data['words'][:5]\n",
    "del words; del k; del data50\n",
    "\n",
    "def word_score2(word,allnum,num):\n",
    "    a =[]\n",
    "    for j in range(len(data)):\n",
    "        if word in data['words'][j]:\n",
    "            a.append(data.iloc[j])\n",
    "    a = pd.DataFrame(a).reset_index(drop=True)\n",
    "    a['cw'] = word\n",
    "    a = a[['cw','date','title','text','category','url','words']]\n",
    "    aa = a['words']\n",
    "    #a2 = [i.replace(\"'\",\"\").replace('[','').replace(']','').replace(' ','').split(',') for i in aa] #words가 텍스트 형식으로 되어 있을 경우\n",
    "    a2 = a['words'] #words가 list로 되어 있을 경우\n",
    "    #score구하기\n",
    "    avg_dist = []\n",
    "    dist = []\n",
    "    dist_dist = []\n",
    "    for i in tqdm(range(len(a2))):\n",
    "        for k in a2[i]:\n",
    "            try:\n",
    "                 # 비교하여 similarity 구하기\n",
    "                dist_dist.append(embedding_model.similarity(word, k))\n",
    "            except:\n",
    "                dist_dist.append(0)\n",
    "            dist2 = np.array(dist_dist)\n",
    "            dist.append(sum(dist2))\n",
    "            dist_dist = []\n",
    "        if len(dist) > 1000:\n",
    "            dist = sorted(dist, reverse=True)[:1000]\n",
    "        avg_dist.append(np.mean(dist))\n",
    "        dist = []\n",
    "    avg_dist\n",
    "    a['score'] = avg_dist\n",
    "    #이상치 경계 구하기\n",
    "    q1 = np.percentile(a['score'], 25)\n",
    "    q3 = np.percentile(a['score'],75)\n",
    "    iqr = q3-q1\n",
    "    outlier = q1 -  1.5 * iqr\n",
    "    print(outlier, ' 값 이하 제거 필요')\n",
    "    j=0\n",
    "    for k in a['score']:\n",
    "        if k < outlier:\n",
    "            j +=1\n",
    "    print('이상치 ', j, '개 있음')\n",
    "    plt.subplot(int('1'+ str(allnum) + str(num))) #박스플랏 바꿔야함\n",
    "    sns.boxplot( data = a['score'])\n",
    "    plt.title(word)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return a\n",
    "###정제된 키워드별 기사들로 각각 토픽모델링 해보기\n",
    "\n",
    "#이상치 자르기\n",
    "def cut_row(word):\n",
    "    # word단어가 포함된 기사만 가져오기\n",
    "    a =[]\n",
    "    for j in range(len(data)):\n",
    "        if word in data['words'][j]:\n",
    "            a.append(data.iloc[j])\n",
    "    a = pd.DataFrame(a).reset_index(drop=True)\n",
    "    a['cw'] = word\n",
    "    a = a[['cw','date','title','text','category','url','words']]\n",
    "    a2 = a['words']\n",
    "    #score 구하기\n",
    "    avg_dist = []\n",
    "    dist = []\n",
    "    dist_dist = []\n",
    "    for i in tqdm(range(len(a2))):\n",
    "        for k in a2[i]:\n",
    "            try:\n",
    "                 # 비교하여 similarity 구하기\n",
    "                dist_dist.append(embedding_model.similarity(word, k))\n",
    "            except:\n",
    "                dist_dist.append(0)\n",
    "            dist2 = np.array(dist_dist)\n",
    "            dist.append(sum(dist2))\n",
    "            dist_dist = []\n",
    "        if len(dist) > 1000:\n",
    "            dist = sorted(dist, reverse=True)[:1000]\n",
    "        avg_dist.append(np.mean(dist))\n",
    "        dist = []\n",
    "    a['score'] = avg_dist\n",
    "\n",
    "    #이상치 구하기\n",
    "    q1 = np.percentile(a['score'], 25)\n",
    "    q3 = np.percentile(a['score'],75)\n",
    "    iqr = q3-q1\n",
    "    outlier = q1 -  1.5 * iqr\n",
    "    print(outlier, ' 값 이하 제거 필요')\n",
    "    j=0\n",
    "    for k in a['score']:\n",
    "        if k < outlier:\n",
    "            j +=1\n",
    "    print('이상치 ', j, '개 제거')\n",
    "    return_data = a[a['score'] > outlier]\n",
    "    return return_data\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in tqdm(range(start, limit, step)):\n",
    "      model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                              id2word=id2word,\n",
    "                                              num_topics=num_topics,\n",
    "                                              random_state=100,\n",
    "                                              update_every=1,\n",
    "                                              chunksize=100,\n",
    "                                              passes=10,\n",
    "                                              alpha='auto',\n",
    "                                              per_word_topics=True)\n",
    "      model_list.append(model)\n",
    "      coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "      coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "def topic(word):\n",
    "    bb2 = cut_row(word)\n",
    "    #news = [i.replace(\"'\", \"\").replace('[', '').replace(']', '').replace(' ', '').split(',') for i in\n",
    "    #        list(bb2['words'])]  # words가 텍스트 형식으로 되어 있을 경우\n",
    "    news = bb2['words']\n",
    "    id2word = corpora.Dictionary(news)\n",
    "    texts = news\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "        coherence_values = []\n",
    "        model_list = []\n",
    "        for num_topics in tqdm(range(start, limit, step)):\n",
    "\n",
    "            model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                    id2word=id2word,\n",
    "                                                    num_topics=num_topics,\n",
    "                                                    random_state=100,\n",
    "                                                    update_every=1,\n",
    "                                                    chunksize=100,\n",
    "                                                    passes=10,\n",
    "                                                    alpha='auto',\n",
    "                                                    per_word_topics=True)\n",
    "            model_list.append(model)\n",
    "            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_values.append(coherencemodel.get_coherence())\n",
    "        return model_list, coherence_values\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=2,\n",
    "                                                            limit=20, step=1)\n",
    "\n",
    "    # Show graph\n",
    "    limit = 20; start = 2; step = 1;\n",
    "    x = range(start, limit, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()\n",
    "    print(coherence_values.index(max(coherence_values)) + 2,'개의 주제가 이상적')\n",
    "    print(word)\n",
    "    #주제 dataframe화 하기\n",
    "    coherence_values.index(max(coherence_values))\n",
    "    optimal_model = model_list[coherence_values.index(max(coherence_values))]\n",
    "    topic_dic = {}\n",
    "    for i in range(coherence_values.index(max(coherence_values)) + 2):\n",
    "        words2 = optimal_model.show_topic(i, topn=20)\n",
    "        topic_dic['topic ' + '{:02d}'.format(i + 1)] = [i[0] for i in words2]\n",
    "    da = pd.DataFrame(topic_dic)\n",
    "    return da\n",
    "\n",
    "###### 이상치 기사 뽑아내기 (박스플랏 연계)\n",
    "def cut_row2(word):\n",
    "    # word단어가 포함된 기사만 가져오기\n",
    "    a =[]\n",
    "    for j in range(len(data)):\n",
    "        if word in data['words'][j]:\n",
    "            a.append(data.iloc[j])\n",
    "    a = pd.DataFrame(a).reset_index(drop=True)\n",
    "    a['cw'] = word\n",
    "    a = a[['cw','date','title','text','category','url','words']]\n",
    "    aa = a['words']\n",
    "    #a2 = [i.replace(\"'\",\"\").replace('[','').replace(']','').replace(' ','').split(',') for i in aa] #words가 텍스트 형식으로 되어 있을 경우\n",
    "    a2 = a['words']\n",
    "    #score 구하기\n",
    "    avg_dist = []\n",
    "    dist = []\n",
    "    dist_dist = []\n",
    "    for i in tqdm(range(len(a2))):\n",
    "        for k in a2[i]:\n",
    "            try:\n",
    "                 # 비교하여 similarity 구하기\n",
    "                dist_dist.append(embedding_model.similarity(word, k))\n",
    "            except:\n",
    "                dist_dist.append(0)\n",
    "            dist2 = np.array(dist_dist)\n",
    "            dist.append(sum(dist2))\n",
    "            dist_dist = []\n",
    "        if len(dist) > 1000:\n",
    "            dist = sorted(dist, reverse=True)[:1000]\n",
    "        avg_dist.append(np.mean(dist))\n",
    "        dist = []\n",
    "    a['score'] = avg_dist\n",
    "\n",
    "    #이상치 구하기\n",
    "    q1 = np.percentile(a['score'], 25)\n",
    "    q3 = np.percentile(a['score'],75)\n",
    "    iqr = q3-q1\n",
    "    outlier = q1 -  1.5 * iqr\n",
    "    print(outlier, ' 값 이하 제거 필요')\n",
    "    j=0\n",
    "    for k in a['score']:\n",
    "        if k < outlier:\n",
    "            j +=1\n",
    "    print('이상치 ', j, '개 제거 해야함')\n",
    "    return_data = a.sort_values(by='score')\n",
    "    return_data.loc[return_data['score'] > outlier,'dummy'] = 1\n",
    "    return_data['dummy'] = return_data['dummy'].fillna(value=0)\n",
    "    for i in range(len(return_data)):\n",
    "        if return_data['dummy'][i] == 0:\n",
    "            print(return_data['title'][i])\n",
    "    return return_data\n",
    "#a = cut_row2('재택근무')\n",
    "\n",
    "###### 토픽 모델링 심화\n",
    "'''print('모델 난이도 : ', optimal_model.log_perplexity(corpus)) #모델 난이도 뽑기\n",
    "coherence_values[1]\n",
    "print(optimal_model.print_topics(20))\n",
    "\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                        id2word=id2word,\n",
    "                                        num_topics=20,\n",
    "                                        random_state=100,\n",
    "                                        update_every=1,\n",
    "                                        chunksize=100,\n",
    "                                        passes=10,\n",
    "                                        alpha='auto',\n",
    "                                        per_word_topics=True)'''\n",
    "\n",
    "def make_topictable_per_doc(ldamodel, corpus):\n",
    "    topic_table = pd.DataFrame()\n",
    "\n",
    "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
    "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list\n",
    "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
    "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
    "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%),\n",
    "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
    "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
    "\n",
    "        # 모든 문서에 대해서 각각 아래를 수행\n",
    "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
    "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
    "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
    "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
    "            else:\n",
    "                break\n",
    "    return(topic_table)\n",
    "\n",
    "word = ['비대면','의료진','소상공인','취약계층','재택근무','원격수업','자영업자','배달','화상회의','고용','경제활동','간호사',\n",
    "         '근로자','실업','금융지원','해고','기본소득','무급휴직','택배','고용유지지원금','노동자','실업자','출퇴근',\n",
    "         '실업률','구직','일자리','유연근무제','특수고용직','비정규직','프랜차이즈','고용노동부','스타트업','유통',\n",
    "         '취업','채용','청년','저소득층','실업급여','유통업계','고용안정지원금','공유오피스']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def most_topic(word2):\n",
    "    def cut_row(word):\n",
    "        # word단어가 포함된 기사만 가져오기\n",
    "        a = []\n",
    "        for j in range(len(data)):\n",
    "            if word in data['words'][j]:\n",
    "                a.append(data.iloc[j])\n",
    "        a = pd.DataFrame(a).reset_index(drop=True)\n",
    "        a['cw'] = word\n",
    "        a = a[['cw', 'date', 'title', 'text', 'category', 'url', 'words']]\n",
    "        a2 = a['words']\n",
    "        # score 구하기\n",
    "        avg_dist = []\n",
    "        dist = []\n",
    "        dist_dist = []\n",
    "        for i in tqdm(range(len(a2))):\n",
    "            for k in a2[i]:\n",
    "                try:\n",
    "                    # 비교하여 similarity 구하기\n",
    "                    dist_dist.append(embedding_model.similarity(word, k))\n",
    "                except:\n",
    "                    dist_dist.append(0)\n",
    "                dist2 = np.array(dist_dist)\n",
    "                dist.append(sum(dist2))\n",
    "                dist_dist = []\n",
    "            if len(dist) > 1000:\n",
    "                dist = sorted(dist, reverse=True)[:1000]\n",
    "            avg_dist.append(np.mean(dist))\n",
    "            dist = []\n",
    "        a['score'] = avg_dist\n",
    "\n",
    "        # 이상치 구하기\n",
    "        q1 = np.percentile(a['score'], 25)\n",
    "        q3 = np.percentile(a['score'], 75)\n",
    "        iqr = q3 - q1\n",
    "        outlier = q1 - 1.5 * iqr\n",
    "        print(outlier, ' 값 이하 제거 필요')\n",
    "        j = 0\n",
    "        for k in a['score']:\n",
    "            if k < outlier:\n",
    "                j += 1\n",
    "        print('이상치 ', j, '개 제거')\n",
    "        return_data = a[a['score'] > outlier]\n",
    "        return return_data\n",
    "    bb = cut_row(word2)\n",
    "    news = bb['words']\n",
    "    time.sleep(0.5)\n",
    "    # 사전 만들기\n",
    "    id2word = corpora.Dictionary(news)\n",
    "    texts = news\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "        coherence_values = []\n",
    "        model_list = []\n",
    "        for num_topics in tqdm(range(start, limit, step)):\n",
    "            model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                    id2word=id2word,\n",
    "                                                    num_topics=num_topics,\n",
    "                                                    random_state=100,\n",
    "                                                    update_every=1,\n",
    "                                                    chunksize=100,\n",
    "                                                    passes=10,\n",
    "                                                    alpha='auto',\n",
    "                                                    per_word_topics=True)\n",
    "            model_list.append(model)\n",
    "            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_values.append(coherencemodel.get_coherence())\n",
    "        return model_list, coherence_values\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=texts, start=2,\n",
    "                                                            limit=20, step=1)\n",
    "    coherence_values.index(max(coherence_values))\n",
    "    optimal_model = model_list[coherence_values.index(max(coherence_values))]\n",
    "\n",
    "    def make_topictable_per_doc(ldamodel, corpus):\n",
    "        topic_table = pd.DataFrame()\n",
    "\n",
    "        # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
    "        for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "            doc = topic_list[0] if ldamodel.per_word_topics else topic_list\n",
    "            doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
    "            # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
    "            # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%),\n",
    "            # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
    "            # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
    "\n",
    "            # 모든 문서에 대해서 각각 아래를 수행\n",
    "            for j, (topic_num, prop_topic) in enumerate(doc):  # 몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
    "                if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
    "                    topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic, 4), topic_list]),\n",
    "                                                     ignore_index=True)\n",
    "                    # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
    "                else:\n",
    "                    break\n",
    "        return (topic_table)\n",
    "    topictable = make_topictable_per_doc(optimal_model, corpus)\n",
    "    topictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\n",
    "    topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
    "    as2 = pd.concat([bb,topictable], axis= 1)\n",
    "    return as2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4159/4159 [00:04<00:00, 936.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08539914717316127  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [06:52<00:00, 22.93s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2755/2755 [00:02<00:00, 1078.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03991921145712016  값 이하 제거 필요\n",
      "이상치  12 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [05:05<00:00, 16.98s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 3282/3282 [00:03<00:00, 1080.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.061005545782359366  값 이하 제거 필요\n",
      "이상치  1 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [05:31<00:00, 18.40s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1927/1927 [00:01<00:00, 1047.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04687500994398512  값 이하 제거 필요\n",
      "이상치  3 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [04:03<00:00, 13.55s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1270/1270 [00:01<00:00, 893.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07134104749937228  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:45<00:00, 12.52s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 707/707 [00:00<00:00, 977.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03355937686890467  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:00<00:00, 10.05s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1373/1373 [00:01<00:00, 880.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07958685054678673  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:49<00:00, 12.73s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1107/1107 [00:01<00:00, 838.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11821194076639355  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:37<00:00, 12.07s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 667/667 [00:00<00:00, 917.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04621121730868663  값 이하 제거 필요\n",
      "이상치  2 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:08<00:00, 10.49s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 3104/3104 [00:03<00:00, 862.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11182072225179987  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [05:51<00:00, 19.51s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1105/1105 [00:01<00:00, 870.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06840500520488983  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:30<00:00, 11.68s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 782/782 [00:00<00:00, 1027.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.051589541392999844  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:10<00:00, 10.59s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1817/1817 [00:01<00:00, 942.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.13498232097686053  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [04:22<00:00, 14.58s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 673/673 [00:00<00:00, 725.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.025616021593259125  값 이하 제거 필요\n",
      "이상치  1 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:14<00:00, 10.83s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 740/740 [00:00<00:00, 1117.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.049675856119085565  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:03<00:00, 10.20s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 416/416 [00:00<00:00, 773.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07293888361668467  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:50<00:00,  9.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 753.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.059296158618553585  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:43<00:00,  9.08s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 390/390 [00:00<00:00, 891.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07583283244649405  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:50<00:00,  9.49s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 533/533 [00:00<00:00, 881.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.09506602612538036  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:54<00:00,  9.68s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 338/338 [00:00<00:00, 868.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03819468507595292  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:45<00:00,  9.18s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1140/1140 [00:01<00:00, 793.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14546475555358668  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:36<00:00, 12.05s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 405/405 [00:00<00:00, 764.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11411311121983755  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:46<00:00,  9.23s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 411/411 [00:00<00:00, 834.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08463939975442544  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:46<00:00,  9.23s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 395/395 [00:00<00:00, 828.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.012393089165636917  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:51<00:00,  9.55s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 501/501 [00:00<00:00, 827.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0011929365240183898  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:51<00:00,  9.54s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2634/2634 [00:02<00:00, 878.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12897320857719022  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [05:27<00:00, 18.21s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 904.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08349035662327031  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:39<00:00,  8.89s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 277/277 [00:00<00:00, 680.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.017594428064485024  값 이하 제거 필요\n",
      "이상치  1 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:59<00:00,  9.97s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 317/317 [00:00<00:00, 695.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06415228163690437  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:57<00:00,  9.85s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 332/332 [00:00<00:00, 948.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06140019396011444  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:48<00:00,  9.38s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 702/702 [00:00<00:00, 893.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004206096992129482  값 이하 제거 필요\n",
      "이상치  1 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:06<00:00, 10.38s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 662/662 [00:00<00:00, 767.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06238145396540229  값 이하 제거 필요\n",
      "이상치  1 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:13<00:00, 10.74s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2331/2331 [00:02<00:00, 919.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.098985472028841  값 이하 제거 필요\n",
      "이상치  3 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [04:57<00:00, 16.50s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1082/1082 [00:01<00:00, 910.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1311999387301442  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:42<00:00, 12.33s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1179/1179 [00:01<00:00, 873.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.16214043247199855  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:44<00:00, 12.46s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1313/1313 [00:01<00:00, 740.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11078447691268392  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:52<00:00, 12.91s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 711/711 [00:00<00:00, 986.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0667239524747211  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [03:05<00:00, 10.32s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 290/290 [00:00<00:00, 745.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04417604146044288  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:54<00:00,  9.69s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 384/384 [00:00<00:00, 786.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006010272427010355  값 이하 제거 필요\n",
      "이상치  2 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:56<00:00,  9.79s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 88/88 [00:00<00:00, 760.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12947362301414475  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:35<00:00,  8.63s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 907.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002204755864521457  값 이하 제거 필요\n",
      "이상치  0 개 제거\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [02:31<00:00,  8.41s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in word:\n",
    "    most_topic123 = most_topic(i)\n",
    "    most_topic123.to_excel('C:/Users/USER/Desktop/1~8newsurl/most_topic_list/' + str(i) +'.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
