{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-91d49cc1be2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimport_ipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClassification_Function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClassification_Function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import Classification_Function \n",
    "import tensorflow as tf\n",
    "from imp import reload\n",
    "reload(Classification_Function)\n",
    "from Classification_Function import *\n",
    "\n",
    "\n",
    "file_path=\"MASK_File/마스크_20_1030.xlsx\"\n",
    "train_df_origin=pd.read_excel(file_path)\n",
    "train_df=train_df_origin[[\"goods_nm\"]]\n",
    "\n",
    "train_df=train_text_preprocessing(train_df)\n",
    "\n",
    "stop=pd.read_table(\"stopwords_korean.txt\",header=None)\n",
    "stopwords=stop[0].tolist()\n",
    "\n",
    "\n",
    "print(\"tokenizer\")\n",
    "print(\"============================\")\n",
    "X_train=tokenizer(train_df,stopwords)\n",
    "X_dict={}\n",
    "print(\"Vocab indexing\")\n",
    "print(\"============================\")\n",
    "X_train,X_dict=vocab_indexing(X_train)  \n",
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = 30)\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "model = load_model(\"train_model_adam_1023_Mask.h5\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Prediction\")\n",
    "print(\"============================\")\n",
    "with tf.device('/cpu:0'):\n",
    "    \n",
    "    predict=model.predict(X_train)\n",
    "    predict_labels = np.argmax(predict, axis=1)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "label_table=pd.read_excel(\"마스크 라벨.xlsx\")\n",
    "Label=pd.DataFrame(label_table)\n",
    "Label=dict(zip(Label[\"KF\"].tolist(),Label[\"Label\"].tolist()))\n",
    "\n",
    "\n",
    "return_label={}\n",
    "for i in tqdm(range(len(label_table))):\n",
    "    return_label.setdefault(label_table.iloc[i]['Label'],label_table.iloc[i]['KF'])\n",
    "    \n",
    "\n",
    "goods_name=train_df['goods_nm']\n",
    "goods=goods_name.tolist()\n",
    "\n",
    "predict_series={\"상품명 \":[], \"예측한 코드 \" : []}\n",
    "predict_Table=pd.DataFrame(predict_series)\n",
    "num=0\n",
    "\n",
    "def largest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)\n",
    "\n",
    "\n",
    "def return_label_2(label):\n",
    "    result=[]\n",
    "    for i in range(len(label[0])):\n",
    "        for k,v in Label.items():\n",
    "            if v==label[0][i]:\n",
    "                result.append(k)\n",
    "    return result\n",
    "\n",
    "print(\"Excel 생성중\")\n",
    "\n",
    "\n",
    "predict_series={ \"예측한 라벨 1 \" : [], \"예측 확률 1 \": [], \"예측한 라벨 2 \" : [], \"예측 확률 2 \": [], \"예측한 라벨 3 \" : [], \"예측 확률 3 \": [], }\n",
    "predict_Table=pd.DataFrame(predict_series)\n",
    "print(\"============================\")\n",
    "for i in tqdm(range(len(predict_labels))):   \n",
    "    num=num+1\n",
    "    new_data={\"예측한 라벨 1 \" : return_label_2(largest_indices(predict[i],3))[0],\n",
    "              \"예측 확률 1 \" :predict[i][largest_indices(predict[i],3)][0], \n",
    "              \"예측한 라벨 2 \" : return_label_2(largest_indices(predict[i],3))[1],\n",
    "              \"예측 확률 2 \" : predict[i][largest_indices(predict[i],3)][1],\n",
    "              \"예측한 라벨 3 \" : return_label_2(largest_indices(predict[i],3))[2],\n",
    "              \"예측 확률 3 \" : predict[i][largest_indices(predict[i],3)][2],\n",
    "              \n",
    "             }\n",
    "    predict_Table=predict_Table.append(new_data,ignore_index=True)\n",
    "\n",
    "result=pd.concat([train_df_origin,predict_Table],axis=1)\n",
    "output_path=file_path.replace(\".xlsx\",\"_result.xlsx\")\n",
    "csv_path=file_path.replace(\".xlsx\",\"_result.csv\")\n",
    "result.to_excel(output_path)\n",
    "result.to_csv(csv_path,encoding=\"UTF-8\")\n",
    "\n",
    "\n",
    "print(\"작업 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
