{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time # 코드 실행시간 알림 용\n",
    "from  tkinter import *\n",
    "from tkinter import filedialog\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(train_df,stopwords): ## 상품명 csv 파일로 만든 DataFrame을 받아 토큰화된 2차원 List로 변환\n",
    "    okt=Okt()\n",
    "    X_train = []\n",
    "    for sentence in tqdm(train_df['goods_nm']):\n",
    "        temp_X = []\n",
    "        temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "        temp_X = [word.lower() for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "    return(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_indexing(X_train): ## 토큰화된 2차원 List와 Vocab File을 받아 Vocab 기준으로 Indexing\n",
    "    vocab_file=file_select(\"Vocab\")\n",
    "    vocab_df = pd.read_csv(vocab_file, sep=',')\n",
    "    X_dict={}\n",
    "    for i in tqdm(range(len(X_train))):\n",
    "        for j in range(len(X_train[i])):\n",
    "            if (vocab_df['word']==X_train[i][j]).any():           \n",
    "                if X_train[i][j] not in X_dict:\n",
    "                    X_dict[X_train[i][j]]=vocab_df[vocab_df['word'].isin([X_train[i][j]])]['index'].values[0]\n",
    "                X_train[i][j] = vocab_df[vocab_df['word'].isin([X_train[i][j]])]['index'].values[0]\n",
    "            else:\n",
    "                new_data={'word':X_train[i][j],'index':len(vocab_df)+2}\n",
    "                vocab_df=vocab_df.append(new_data, ignore_index=True)\n",
    "                print(\"Vocab에 없는 단어 발견 : {} \".format(X_train[i][j]))\n",
    "                X_dict[X_train[i][j]]=len(vocab_df)+2\n",
    "                X_train[i][j]=len(vocab_df)+2\n",
    "                print(vocab_df.tail())\n",
    "    vocab_df.to_csv(vocab_file, sep=',',index=False)    \n",
    "    return(X_train,X_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(train_df,): ##쓸모없는 기호 제거 및 중복된 상품명 제거\n",
    "    train_df['goods_nm'] = train_df['goods_nm'].str.replace(r'[-=+★,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+', \" \", regex=True)\n",
    "    train_df['goods_nm'] = train_df['goods_nm'].str.replace(r'\\t+', \" \", regex=True)\n",
    "    train_df['goods_nm'] = train_df['goods_nm'].str.replace(r'[\\\\n]+',\" \", regex=True) \n",
    "    train_df['goods_nm'] = train_df['goods_nm'].str.replace(r'[0-9]',\" \", regex=True) ##숫자 제거\n",
    "    train_df.drop_duplicates(subset=['goods_nm'], inplace=True) \n",
    "    return(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Labeling(y_train):\n",
    "    ##Label=file_select(\"Label\")\n",
    "    Label=\"label.csv\"\n",
    "    Label_df=pd.read_csv(Label, sep=',')\n",
    "    prdlist=Label_df['prices_prdlst_nm'].unique()\n",
    "    yy_train=[]\n",
    "    for i in tqdm(range(len(y_train))):\n",
    "        for j in range(len(prdlist)):            \n",
    "            try:\n",
    "                if y_train[i]==Label_df['prices_prdlst_nm'][j]:                                 \n",
    "                    yy_train.append(Label_df['Label'][j])\n",
    "                    break\n",
    "            except KeyError :\n",
    "                print(\"Key Error j :값 {}\".format(j))\n",
    "    yy_train=np.array(yy_train)\n",
    "    return(yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Labeling2(y_train):\n",
    "    ##Label=file_select(\"Label\")\n",
    "    Label=\"label.csv\"\n",
    "    Label_df=pd.read_csv(Label, sep=',')\n",
    "    print(Label_df)\n",
    "    prdlist=Label_df['prices_prdlst_nm'].unique()\n",
    "    yy_train=[]\n",
    "    Label_index=0\n",
    "    for i in tqdm(range(len(y_train))):\n",
    "        try:\n",
    "            Label_index=Label_df[Label_df['prices_prdlst_nm']==y_train[i]]\n",
    "            Label_index2=Label_index.iloc[0][2]\n",
    "            yy_train.append(Label_index2)           \n",
    "        except :\n",
    "            print(\"값은 {}이고 Label은 {}이다.\".format(i,y_train[i]))\n",
    "    yy_train=np.array(yy_train)\n",
    "    return(yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_select_to_csv() : ##폴더 전체 파일을 선택해 csv로 병합하여 불러온다\n",
    "    root = Tk()\n",
    "    root.dirName=filedialog.askdirectory();\n",
    "    print (root.dirName);\n",
    "    input_file=root.dirName\n",
    "    root.destroy()\n",
    "    \n",
    "    allFile_list = glob.glob(os.path.join(input_file, '*.csv'))\n",
    "    print(allFile_list)\n",
    "    allData = []\n",
    "    output_file = input_file+'/'+str(time.time())+'result.csv'\n",
    "    \n",
    "    for file in allFile_list:\n",
    "        df = pd.read_csv(file,sep=',') # for구문으로 csv파일들을 읽어 들인다\n",
    "        allData.append(df) # 빈 리스트에 읽어 들인 내용을 추가한다\n",
    "    \n",
    "    dataCombine = pd.concat(allData, axis=0, ignore_index=True) # concat함수를 이용해서 리스트의 내용을 병합\n",
    "    # axis=0은 수직으로 병합함. axis=1은 수평. ignore_index=True는 인데스 값이 기존 순서를 무시하고 순서대로정렬되도록 한다.\n",
    "    \n",
    "    dataCombine.to_csv(output_file, index=False) # to_csv함수로 저장한다. 인데스를 빼려면 False로 설정\n",
    "    train_df = pd.read_csv(output_file, sep=',')\n",
    "    train_df=train_df.loc[:,['goods_nm','prices_prdlst_nm']]\n",
    "    return(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_select_to_csv(): \n",
    "    root = Tk()\n",
    "    root.filename =  filedialog.askopenfilename(initialdir = \"/\", title = \"Train 파일 선택\")\n",
    "    print (root.filename)\n",
    "    train_filename=root.filename\n",
    "    root.destroy()\n",
    "    \n",
    "    train_df = pd.read_csv(train_filename, sep=',', error_bad_lines=False)\n",
    "    train_df=train_df.loc[:,['goods_nm','prices_prdlst_nm']]\n",
    "    return(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_select(purpose):\n",
    "    root = Tk()\n",
    "    root.filename =  filedialog.askopenfilename(initialdir = \"/\", title = purpose+\" 파일 선택\")\n",
    "    print (root.filename)\n",
    "    file_name=root.filename\n",
    "    root.destroy\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Label(Label_var,File_name):\n",
    "    root = Tk()\n",
    "    root.filename = filedialog.askopenfilename(initialdir = \"/\", title = \"라벨 만들 파일 선택\")\n",
    "    print ( root.filename)\n",
    "    Label_file= pd.read_csv(root.filename, sep = ',')\n",
    "    Label_df=Label_file.loc[:,[Label_var]]\n",
    "    Label_list=Label_df[Label_var].unique()\n",
    "    Label_df=pd.DataFrame(index=range(0,len(Label_list)), columns=[Label_var, 'Label'])\n",
    "    for i in tqdm(range(len(Label_list))):\n",
    "        Label_df[Label_var][i]=Label_list[i]\n",
    "        Label_df['Label'][i]=i\n",
    "    Label_df.to_csv(File_name,sep=\",\",na_rep='Nan', encoding ='utf-8-sig')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_select_to_csv_var(Product_name,Label): \n",
    "    root = Tk()\n",
    "    root.filename =  filedialog.askopenfilename(initialdir = \"/\", title = \"Train 파일 선택\")\n",
    "    print (root.filename)\n",
    "    train_filename=root.filename\n",
    "    root.destroy()\n",
    "    \n",
    "    train_df = pd.read_csv(train_filename, sep=',', error_bad_lines=False)\n",
    "    train_df=train_df.loc[:,[Product_name,Label]]\n",
    "    return(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Labeling_var(y_train,Label_var):\n",
    "    Label_file=file_select(\"Label\")\n",
    "    Label_df=pd.read_csv(Label_file, sep=',')\n",
    "    prdlist=Label_df[Label_var].unique()\n",
    "    yy_train=[]\n",
    "    for i in tqdm(range(len(y_train))):\n",
    "        for j in range(len(prdlist)):            \n",
    "            try:\n",
    "                if y_train[i]==Label_df[Label_var][j]:                                 \n",
    "                    yy_train.append(Label_df['Label'][j])\n",
    "                    break\n",
    "            except KeyError :\n",
    "                print(\"Key Error j :값 {}\".format(j))\n",
    "    yy_train=np.array(yy_train)\n",
    "    den=len(prdlist)\n",
    "    return(yy_train,den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
