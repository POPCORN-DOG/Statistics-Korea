{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Classification_Function.ipynb\n",
      "importing Jupyter notebook from Classification_Function.ipynb\n"
     ]
    }
   ],
   "source": [
    "# !pip install import_ipynb\n",
    "import import_ipynb\n",
    "import Classification_Function \n",
    "from imp import reload\n",
    "reload(Classification_Function)\n",
    "from Classification_Function import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"농축 학습데이터 계통 및 형태소 추출 ver1.2.xlsx\")\n",
    "\n",
    "df[\"Label\"]=df[\"a_prices_prdlst_nm\"]+\" \"+df[\"정답여부\"]\n",
    "\n",
    "df_1=df[df[\"구분\"]=='계통']\n",
    "\n",
    "df_2=df[df[\"구분\"]=='형태소']\n",
    "\n",
    "df_1=df_1[['구분',\"goods_nm\",\"Label\"]]\n",
    "\n",
    "df_2=df_2[['구분',\"goods_nm\",\"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구분</th>\n",
       "      <th>goods_nm</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>형태소</td>\n",
       "      <td>#10/6 49_900원# [푸드조아] 20년 햅쌀 황금미가 20kg</td>\n",
       "      <td>쌀 Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>형태소</td>\n",
       "      <td>#6/23 단하루 39_900원# [홍천철원] 19년산 햇빛담은쌀 20kg</td>\n",
       "      <td>쌀 Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>형태소</td>\n",
       "      <td>#6/26~ 중소기업쿠폰+현대카드20%쿠폰 최종가 34_900원# [명가미곡]지리산...</td>\n",
       "      <td>쌀 Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>형태소</td>\n",
       "      <td>('19년 햅쌀) 굿뜨래 평안쌀(10KG)</td>\n",
       "      <td>쌀 Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>형태소</td>\n",
       "      <td>(17년 햅쌀) 경기도 대왕님표 여주쌀 4kg</td>\n",
       "      <td>쌀 Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145146</th>\n",
       "      <td>형태소</td>\n",
       "      <td>펠리칸 LED 방폭라이트 1965 21Lm 140x19mm 2xAAA (1EA)</td>\n",
       "      <td>생화 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145147</th>\n",
       "      <td>형태소</td>\n",
       "      <td>펠리칸 LED 방폭라이트 2010 109Lm 178x45mm 3xC (1EA)</td>\n",
       "      <td>생화 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145148</th>\n",
       "      <td>형태소</td>\n",
       "      <td>펠리칸 LED 방폭라이트 2410 126Lm 178x45mm 4xAA (1EA)</td>\n",
       "      <td>생화 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145149</th>\n",
       "      <td>형태소</td>\n",
       "      <td>펠리칸 LED라이트 4000 251Lm 12 D형x8EA (1EA)</td>\n",
       "      <td>생화 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145150</th>\n",
       "      <td>형태소</td>\n",
       "      <td>펠리칸 LED비상등 라이트 3310ELS 3xAA 4.5V 156mm (1EA)</td>\n",
       "      <td>생화 N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145151 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         구분                                           goods_nm Label\n",
       "0       형태소             #10/6 49_900원# [푸드조아] 20년 햅쌀 황금미가 20kg   쌀 Y\n",
       "1       형태소          #6/23 단하루 39_900원# [홍천철원] 19년산 햇빛담은쌀 20kg   쌀 Y\n",
       "2       형태소  #6/26~ 중소기업쿠폰+현대카드20%쿠폰 최종가 34_900원# [명가미곡]지리산...   쌀 Y\n",
       "3       형태소                            ('19년 햅쌀) 굿뜨래 평안쌀(10KG)   쌀 Y\n",
       "4       형태소                          (17년 햅쌀) 경기도 대왕님표 여주쌀 4kg   쌀 Y\n",
       "...     ...                                                ...   ...\n",
       "145146  형태소       펠리칸 LED 방폭라이트 1965 21Lm 140x19mm 2xAAA (1EA)  생화 N\n",
       "145147  형태소        펠리칸 LED 방폭라이트 2010 109Lm 178x45mm 3xC (1EA)  생화 N\n",
       "145148  형태소       펠리칸 LED 방폭라이트 2410 126Lm 178x45mm 4xAA (1EA)  생화 N\n",
       "145149  형태소              펠리칸 LED라이트 4000 251Lm 12 D형x8EA (1EA)  생화 N\n",
       "145150  형태소       펠리칸 LED비상등 라이트 3310ELS 3xAA 4.5V 156mm (1EA)  생화 N\n",
       "\n",
       "[145151 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(\"Data_계통.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "df_2.to_csv(\"Data_형태소.csv\", sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_1=df_1[\"Label\"]\n",
    "\n",
    "# 라벨 중복제거\n",
    "Label_list=Label_1.unique()\n",
    "\n",
    "# index = 번호 , \n",
    "Label_df_1=pd.DataFrame(index=range(0,len(Label_list)), columns=[\"Index\",\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_2=df_2[\"Label\"]\n",
    "\n",
    "Label_list2=Label_2.unique()\n",
    "\n",
    "Label_df_2=pd.DataFrame(index=range(0,len(Label_list2)), columns=[\"Index\",\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 6642.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(Label_list))):\n",
    "    Label_df_1[\"Label\"][i]=Label_list[i]\n",
    "    Label_df_1[\"Index\"][i]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 8610.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(Label_list2))):\n",
    "    Label_df_2[\"Label\"][i]=Label_list2[i]\n",
    "    Label_df_2[\"Index\"][i]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_df_1.to_csv(\"Data_계통_Label.csv\",sep=\",\", encoding=\"utf-8-sig\" )\n",
    "Label_df_2.to_csv(\"Data_형태소_Label.csv\",sep=\",\", encoding=\"utf-8-sig\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_indexing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-65908f138400>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mX_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mXX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mXX_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mdrop_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_indexing' is not defined"
     ]
    }
   ],
   "source": [
    "# sample 무작위 심플 추출 / frac = 0.1 ~ 1 전체 개수의 비율 만큼 샘플을 반환하려 할 경우 사용 됨 \n",
    "# frac = 1 / 무작위 재배치\n",
    "df_1=df_1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# (Classification_Function) 쓸모없는 기호 제거 및 중복된 상품명 제거\n",
    "df_1=text_preprocessing(df_1)\n",
    "\n",
    "# na값 제거\n",
    "df_1=df_1.dropna()\n",
    "\n",
    "# stopwods 제거\n",
    "stop = pd.read_table(\"stopwords_korean.txt\", sep=\"\\t\")\n",
    "\n",
    "# stopwords(배제어) list 생성\n",
    "stopwords=stop[\"이\"].tolist()\n",
    "\n",
    "# (Classification_Function) 형태소 분석\n",
    "X_train=tokenizer(df_1,stopwords)\n",
    "\n",
    "# 분석을 위해 list 형태를 array 형태로 변환 \n",
    "y_train=np.array(df_1[\"Label\"])\n",
    "\n",
    "\n",
    "X_dict={}\n",
    "XX_train,X_dict=vocab_indexing(X_train)     \n",
    "XX_train\n",
    "\n",
    "# 상품명이 적혀있지 않은 데이터 인덱스를 가져온다.\n",
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측행 제거\n",
    "XX_train = np.delete(XX_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "\n",
    "yy_train=[]\n",
    "yy_train,den=Labeling_var(y_train,'Label')\n",
    "\n",
    "# pad_sequences 길이가 같지 않고 적거나 많을 때 일정한 길이로 맞춰주기 위해 사용한다.\n",
    "# maxlen = 32 : 시퀀스의 최대길이를 32로 지정하고 초과한 경우 각 시퀀스의 앞쪽에서 자른다.\n",
    "# why 32 : \n",
    "XX_train = pad_sequences(XX_train, maxlen = 32)\n",
    "\n",
    "import time # 시간 관련 패키지\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras import optimizers\n",
    "\n",
    "# 딥러닝 구조를 결정한다(모델을 설정하고 실행하는 부분)\n",
    "# sequential: 층을 쌓을 수 있게 한다.\n",
    "# Embedding: 워드 임베딩이란 텍스트 내의 단어들을 밀집 벡터(dense vector)로 만드는 것.\n",
    "# Embedding(불러온 단어의 총 개수(단어사전의 크기), 상품명 당 단어 수)\n",
    "# LSTM(상품명 당 단어 수, 기타 옵션)\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 128,)) \n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(den, activation='softmax'))\n",
    "\n",
    "# https://3months.tistory.com/424\n",
    "# EarlyStopping: 성능이 더이상 증가하지 않을 때 학습을 중지시키게 한다.\n",
    "# monitor: 손실 혹은 정확도 중 어떤 것을 기준으로 할지 설정하는 역할\n",
    "# val_loss: validation_loss 손실\n",
    "# mode: min, mas ex) 손실을 최소화 시키는 방향으로 training이 진행될 때\n",
    "# verbose=1: 언제 keras에서 training을 멈추었는지 화면에 출력\n",
    "# patience: 성능이 증가하지 않는 epoch을 몇 번이나 허용할 것인가 정의 (주관적인 기준)\n",
    "# modelCheckpoint: 모델 저장하기 위한 함수\n",
    "# save_best_only: 가장 좋은 모델만 저장. (h5는 모델 저장할 때 붙는 확장자 같은 역할)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "checkpoint_path='train_model_adam_1109_농축수산.h5'\n",
    "mc = ModelCheckpoint(chekpoint_path, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "# model.compile: 앞서 지정한 모델이 효과적으로 구현될 수 있게 여러가지 환경을 설정해 주면서 컴파일하는 부분.\n",
    "# optimizer: 최적화 방법\n",
    "# optimizer='adam': adam은 현재 가장 많이 사용되는 고급 경사 하강법\n",
    "# loss: 오챠 함수\n",
    "# loss='sparse_categorical_crossentropy': 3개 이상의 범주형 교차 엔트로피(일반적인 분류)\n",
    "# metrics: 모델이 컴파일될 때 모델 수행 결과를 나타내게끔 설정하는 부분\n",
    "# metrics=['acc']: 정확도 출력\n",
    "start = time.time()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "# cpu 동작\n",
    "with tf.device('/cpu:0'):\n",
    "    # fit: 모델 수행\n",
    "    # epochs: 모든 샘플에 대해 한 번 실행되는 것\n",
    "    # callbacks: epochs가 끝날 때마다의 중간 저장기능\n",
    "    # batch_size: 샘플을 한 번에 몇 개씩 처리할 지를 정해준다. ex) batch_size=32:전체 샘플을 32개씩 끊어서 집어넣어라 \n",
    "    # validation_split: XX_train과 yy_train에서 검증데이터로 사용하기 위한 분리 비율\n",
    "    history = model.fit(XX_train, yy_train, epochs=100, callbacks=[es, mc], batch_size=32, validation_split=0.1)\n",
    "\n",
    "# time.time() - start : 현재시각 - 시작시간 = 실행 시간\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
